{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de región de confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando método DogLeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la \n",
    "from functools import partial\n",
    "\n",
    "def Modify_hessian(x_k,H,beta=1e-3):\n",
    "    B_k=H(x_k)  #Esto saca la aproximación del hessiano\n",
    "    if min(B_k.diagonal())>0:\n",
    "        tau=0\n",
    "    else:\n",
    "        tau=-min(B_k.diagonal())+beta\n",
    "    Aux=B_k+tau*np.identity(B_k.shape[0])\n",
    "    for i in range(1000):\n",
    "        try:\n",
    "            la.cholesky(Aux)\n",
    "            B_k=Aux\n",
    "            return B_k\n",
    "            break\n",
    "        except:\n",
    "            tau=max(2*tau,beta)\n",
    "            Aux=B_k+tau*np.identity(B_k.shape[0])\n",
    "    \n",
    "def resolver_taw_para_dogleg(pu, pb, delta):\n",
    "    a = np.dot(pu-pb, pu-pb)\n",
    "    b = -2 * (2*np.dot(pu, pu) + np.dot(pb, pb) - 3*np.dot(pu, pb))\n",
    "    c = np.dot(2*pu-pb, 2*pu-pb) - delta**2\n",
    "    d = np.sqrt(b**2 - 4*a*c)\n",
    "    t1 = (-b + d) / (2*a)\n",
    "    t2 = (-b - d) / (2*a)\n",
    "    if 0 <= t1 <= 2:\n",
    "        if 0 <= t2 <= 2:\n",
    "            return min(t1, t2)\n",
    "        return t1\n",
    "    elif 0 <= t2 <= 2:\n",
    "        return t2\n",
    "    else:\n",
    "        raise ArithmeticError('Tau no está en [0,2]: %d %d', t1, t2)\n",
    "    \n",
    "def Dog_Leg_method(x_k,Hessian,grad,delta): #se ocupa el punto, el hessiano y el gradiente para poder calcular el \n",
    "    pb=-1*np.dot(la.inv(Hessian),grad(x_k))\n",
    "    if la.norm(pb)<=delta:\n",
    "        return pb\n",
    "    pu=-1*(np.dot(grad(x_k).T,grad(x_k))/np.dot(grad(x_k).T,np.dot(Hessian,grad(x_k))))*grad(x_k)\n",
    "    if la.norm(pu) >= delta:\n",
    "        return (delta / la.norm(pu)*(1-1e-3) *pu)\n",
    "    taw = resolver_taw_para_dogleg(pu, pb, delta)\n",
    "    if taw <= 1:\n",
    "        return taw * pu\n",
    "    else:\n",
    "        return pu + (taw - 1)*(pb - pu)\n",
    "    \n",
    "\n",
    "def model(f, grad, b, x_k, p, delta):  #f es la funcion objetivo, grad el gradiente, b la f\n",
    "    if la.norm(p) > delta + 1e-9: #El error ese es por los cálculos de tanto producto punto que acarrea demasiados errores \n",
    "        raise ArithmeticError('P no debe de ser mas grande que delta:', p, la.norm(p), delta) #si ya se pasa demasiado de la región de confianza entonces ya hay error \n",
    "    return f(x_k) + np.dot(grad(x_k).T, p) + 0.5*np.dot(np.dot(p.T,b), p)\n",
    "\n",
    "def trust_region_Dogleg(f, g, hf, x0, delta_0, max_delta, etha, eps=1e-5):\n",
    "    x = x0\n",
    "    delta = delta_0\n",
    "    iterations = 0\n",
    "    Hessian=Modify_hessian(x,hf)\n",
    "    while True:\n",
    "        iterations += 1\n",
    "        b = Modify_hessian(x,hf)\n",
    "        p = Dog_Leg_method(x,b,g,delta)\n",
    "        rho = (f(x) - f(x+p)) / (model(f, g, b, x, p, delta) - model(f, g, b, x+p, p, delta))\n",
    "        if rho < .25:\n",
    "            delta = .25 * delta\n",
    "        elif rho >= .75 and np.isclose(la.norm(p), delta, 1e-4):\n",
    "            delta = min(2*delta, max_delta)\n",
    "        if rho > etha:\n",
    "            x = x + p\n",
    "        elif np.allclose(p, np.zeros(p.shape), eps):\n",
    "            result = x + p\n",
    "            break\n",
    "    \n",
    "    return  result, g(result),iterations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rosenbrock para n=2, caso de prueba para el algoritmo\n",
    "def f(datos): #Función objetivo o target function\n",
    "    x,y=datos\n",
    "    return 100*(y-x**2)**2+(1-x)**2\n",
    "\n",
    "def gradiente_f(datos): #gradiente de la función f\n",
    "    g=np.zeros(len(datos))\n",
    "    g[0]=2*(200*datos[0]**3-200*datos[0]*datos[1]+datos[0]-1)\n",
    "    g[1]=200*(datos[1]-datos[0]**2)\n",
    "    return g\n",
    "\n",
    "def hessiano_f(datos):\n",
    "    hes=np.zeros((len(datos),len(datos)))\n",
    "    hes[0][0]=2*(600*datos[0]**2-200*datos[1]+1)\n",
    "    hes[1][0]=-400*datos[0]\n",
    "    hes[0][1]=-400*datos[0]\n",
    "    hes[1][1]=200\n",
    "    return hes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res,grad_res,iteraciones=trust_region_Dogleg(f, gradiente_f, hessiano_f, [-1.2,1],0.5,1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17306 & 4.131708020883563e-06 & 1.8786632936469468e-11\n"
     ]
    }
   ],
   "source": [
    "print(iteraciones, '&' ,la.norm(grad_res), '&' ,f(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_grad(x_k,z,b,grad):\n",
    "    return grad(x_k)+np.dot(b,z)\n",
    "\n",
    "def LSTR_method(x_k,b,grad,delta,grad_model,tol_d,maxiter):\n",
    "    iterations=0\n",
    "    z=np.zeros_like(x_k)\n",
    "    d=-Model_grad(x_k,z,b,grad)\n",
    "    p_k=None\n",
    "    while la.norm(d)>tol_d and iterations<maxiter:\n",
    "        if np.dot(d.T,np.dot(b,d))<=0:\n",
    "            p_k=z-((np.dot(grad(x_k).T,d)+np.dot(z.T,np.dot(b,d)))/np.dot(d.T,np.dot(b,d)))*d\n",
    "            if la.norm(p_k)>delta:\n",
    "                return p_k/la.norm(p_k)*delta\n",
    "        else:\n",
    "            alfa=-(np.dot(grad(x_k).T,d)+np.dot(z.T,np.dot(b,d)))/np.dot(d.T,np.dot(b,d))\n",
    "            z=z+alfa*d\n",
    "            if la.norm(z)>=delta:\n",
    "                p_k=z-((np.dot(grad(x_k).T,d)+np.dot(z.T,np.dot(b,d)))/np.dot(d.T,np.dot(b,d)))*d\n",
    "                if la.norm(p_k)>delta:\n",
    "                    return p_k/la.norm(p_k)*delta\n",
    "            d=-Model_grad(x_k,z,b,grad)\n",
    "            iterations=iterations+1\n",
    "            \n",
    "    return p_k if p_k!=None else z\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trust_region_LSTR(f, g, hf, x0, delta_0, max_delta, etha,grad_model, eps=1e-5,tol_d=1e-4,maxiter=2000):\n",
    "    x = x0\n",
    "    delta = delta_0\n",
    "    iterations = 0\n",
    "    Hessian=Modify_hessian(x,hf)\n",
    "    while True:\n",
    "        iterations += 1\n",
    "        b = Modify_hessian(x,hf)\n",
    "        p = LSTR_method(x,b,g,delta,grad_model,tol_d,maxiter)\n",
    "        rho = (f(x) - f(x+p)) / (model(f, g, b, x, p, delta) - model(f, g, b, x+p, p, delta)+1e-9)\n",
    "        if rho < .25:\n",
    "            delta = .25 * delta\n",
    "        elif rho >= .75 and np.isclose(la.norm(p), delta, 1e-4):\n",
    "            delta = min(2*delta, max_delta)\n",
    "        if rho > etha:\n",
    "            x = x + p\n",
    "        elif np.allclose(p, np.zeros(p.shape), eps):\n",
    "            result = x + p\n",
    "            break\n",
    "    return  result, g(result),iterations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res,grad_res,iteraciones=trust_region_LSTR(f, gradiente_f, hessiano_f, [-1.2,1],0.2,1, 0.2,Model_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99989605 0.99979169] 9.299744119917776e-05 81\n"
     ]
    }
   ],
   "source": [
    "print(res,la.norm(grad_res),iteraciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar las funciones Rosenbruck para n=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definamos la función que vamos a usar \n",
    "def rosen(x): #La función de rosembruck en general\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "def r_der(x):\n",
    "        xm = x[1:-1]\n",
    "        xm_m1 = x[:-2]\n",
    "        xm_p1 = x[2:]\n",
    "        der =np.zeros(x.shape)\n",
    "        der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "        der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "        der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "        return der\n",
    "\n",
    "def rosen_hess(x):\n",
    "        H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)\n",
    "        diagonal = np.zeros(len(x))\n",
    "        diagonal[0] = 1200*x[0]-400*x[1]+2\n",
    "        diagonal[-1] = 200\n",
    "        diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]\n",
    "        H = H + np.diag(diagonal)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_inicial=np.ones(100)\n",
    "p_inicial[1]=-1.2\n",
    "p_inicial[98]=-1.2\n",
    "\n",
    "res,grad_res,iteraciones=trust_region_Dogleg(rosen, r_der, rosen_hess, p_inicial,0.5,1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogleg\n",
      "27007 & 1.485514026182182e-05 & 1.9441371533020164e-10\n"
     ]
    }
   ],
   "source": [
    "print(\"Dogleg\")\n",
    "\n",
    "print(iteraciones, '&' ,la.norm(grad_res), '&' ,rosen(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res,grad_res,iteraciones=trust_region_LSTR(rosen, r_der, rosen_hess, p_inicial,0.5,1, 0.2,Model_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTR\n",
      "90 & 9.989178293055755e-05 & 5.0517939853093575e-09\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTR\")\n",
    "print(iteraciones, '&' ,la.norm(grad_res), '&' ,rosen(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
